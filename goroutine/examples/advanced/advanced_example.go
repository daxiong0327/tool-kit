package main

import (
	"fmt"
	"math/rand"
	"sync"
	"time"

	"github.com/daxiong0327/tool-kit/goroutine"
)

// æ¨¡æ‹Ÿä¸€ä¸ªå¯èƒ½å¤±è´¥çš„æœåŠ¡
type Service struct {
	name        string
	successRate float64
	mu          sync.RWMutex
}

func NewService(name string, successRate float64) *Service {
	return &Service{
		name:        name,
		successRate: successRate,
	}
}

func (s *Service) Call() error {
	s.mu.RLock()
	successRate := s.successRate
	s.mu.RUnlock()

	if rand.Float64() < successRate {
		return nil
	}
	return fmt.Errorf("æœåŠ¡ %s è°ƒç”¨å¤±è´¥", s.name)
}

func (s *Service) SetSuccessRate(rate float64) {
	s.mu.Lock()
	defer s.mu.Unlock()
	s.successRate = rate
}

func main() {
	fmt.Println("=== åç¨‹ç®¡ç†æ¨¡å—é«˜çº§ç¤ºä¾‹ ===")

	// ç¤ºä¾‹1ï¼šå¾®æœåŠ¡æ¶æ„ä¸­çš„åç¨‹ç®¡ç†
	fmt.Println("\n1. å¾®æœåŠ¡æ¶æ„ä¸­çš„åç¨‹ç®¡ç†:")
	microserviceExample()

	// ç¤ºä¾‹2ï¼šé«˜å¹¶å‘ä»»åŠ¡å¤„ç†
	fmt.Println("\n2. é«˜å¹¶å‘ä»»åŠ¡å¤„ç†:")
	highConcurrencyExample()

	// ç¤ºä¾‹3ï¼šåˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦
	fmt.Println("\n3. åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦:")
	distributedSchedulingExample()

	// ç¤ºä¾‹4ï¼šå®æ—¶ç›‘æ§å’Œå‘Šè­¦
	fmt.Println("\n4. å®æ—¶ç›‘æ§å’Œå‘Šè­¦:")
	realtimeMonitoringExample()

	// ç¤ºä¾‹5ï¼šä¼˜é›…å…³é—­
	fmt.Println("\n5. ä¼˜é›…å…³é—­:")
	gracefulShutdownExample()

	fmt.Println("\nğŸ‰ é«˜çº§ç¤ºä¾‹å®Œæˆï¼")
}

// microserviceExample å¾®æœåŠ¡æ¶æ„ä¸­çš„åç¨‹ç®¡ç†ç¤ºä¾‹
func microserviceExample() {
	// åˆ›å»ºæœåŠ¡
	userService := NewService("ç”¨æˆ·æœåŠ¡", 0.8)
	orderService := NewService("è®¢å•æœåŠ¡", 0.7)
	paymentService := NewService("æ”¯ä»˜æœåŠ¡", 0.9)

	// åˆ›å»ºåç¨‹æ± 
	config := &goroutine.PoolConfig{
		MaxWorkers: 10,
		QueueSize:  100,
		JobTimeout: 5 * time.Second,
	}
	pool := goroutine.NewPool(config)
	defer pool.Stop()

	// è®¾ç½®å´©æºƒæ¢å¤å¤„ç†å™¨
	pool.SetRecoverHandler(func(panicValue interface{}, stack []byte, goroutineID string) {
		fmt.Printf("  ğŸš¨ å¾®æœåŠ¡åç¨‹å´©æºƒ: %v (åç¨‹ID: %s)\n", panicValue, goroutineID)
	})

	// æ¨¡æ‹Ÿç”¨æˆ·è¯·æ±‚å¤„ç†
	for i := 0; i < 20; i++ {
		requestID := fmt.Sprintf("req-%d", i+1)
		pool.SubmitFunc(requestID, func() error {
			return processUserRequest(requestID, userService, orderService, paymentService)
		})
	}

	time.Sleep(2 * time.Second)

	// æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
	stats := pool.GetStats()
	fmt.Printf("  ğŸ“Š å¾®æœåŠ¡ç»Ÿè®¡: æ€»è¯·æ±‚=%d, æˆåŠŸ=%d, å¤±è´¥=%d\n",
		stats.TotalJobs, stats.CompletedJobs, stats.FailedJobs)
}

func processUserRequest(requestID string, userService, orderService, paymentService *Service) error {
	fmt.Printf("  ğŸ”„ å¤„ç†è¯·æ±‚ %s\n", requestID)

	// è°ƒç”¨ç”¨æˆ·æœåŠ¡
	if err := userService.Call(); err != nil {
		return fmt.Errorf("ç”¨æˆ·æœåŠ¡è°ƒç”¨å¤±è´¥: %w", err)
	}

	// è°ƒç”¨è®¢å•æœåŠ¡
	if err := orderService.Call(); err != nil {
		return fmt.Errorf("è®¢å•æœåŠ¡è°ƒç”¨å¤±è´¥: %w", err)
	}

	// è°ƒç”¨æ”¯ä»˜æœåŠ¡
	if err := paymentService.Call(); err != nil {
		return fmt.Errorf("æ”¯ä»˜æœåŠ¡è°ƒç”¨å¤±è´¥: %w", err)
	}

	fmt.Printf("  âœ… è¯·æ±‚ %s å¤„ç†æˆåŠŸ\n", requestID)
	return nil
}

// highConcurrencyExample é«˜å¹¶å‘ä»»åŠ¡å¤„ç†ç¤ºä¾‹
func highConcurrencyExample() {
	executor := goroutine.NewSafeExecutor()

	// åˆ›å»ºé™æµå™¨
	rateLimiter := goroutine.NewRateLimiter(executor, 5, 1*time.Second)
	defer rateLimiter.Stop()

	// åˆ›å»ºç†”æ–­å™¨
	circuitBreaker := goroutine.NewCircuitBreaker(executor, 10, 2*time.Second)

	// åˆ›å»ºé‡è¯•å™¨
	retry := goroutine.NewRetry(executor, 3, 100*time.Millisecond, &goroutine.ExponentialBackoff{
		BaseDelay: 50 * time.Millisecond,
		MaxDelay:  1 * time.Second,
	})

	// æ¨¡æ‹Ÿé«˜å¹¶å‘ä»»åŠ¡
	var wg sync.WaitGroup
	numTasks := 50

	wg.Add(numTasks)
	for i := 0; i < numTasks; i++ {
		taskID := i + 1
		executor.Go(func() {
			defer wg.Done()
			processHighConcurrencyTask(taskID, rateLimiter, circuitBreaker, retry)
		})
	}

	wg.Wait()
	fmt.Println("  âœ… é«˜å¹¶å‘ä»»åŠ¡å¤„ç†å®Œæˆ")
}

func processHighConcurrencyTask(taskID int, rl *goroutine.RateLimiter, cb *goroutine.CircuitBreaker, retry *goroutine.Retry) {
	// é™æµæ£€æŸ¥
	if !rl.Allow() {
		fmt.Printf("  â³ ä»»åŠ¡ %d è¢«é™æµ\n", taskID)
		return
	}

	// ä½¿ç”¨ç†”æ–­å™¨æ‰§è¡Œä»»åŠ¡
	err := cb.Execute(func() error {
		return retry.Execute(func() error {
			// æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
			time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)

			// æ¨¡æ‹Ÿå¤±è´¥
			if rand.Float64() < 0.3 {
				return fmt.Errorf("ä»»åŠ¡ %d æ‰§è¡Œå¤±è´¥", taskID)
			}

			fmt.Printf("  âœ… ä»»åŠ¡ %d æ‰§è¡ŒæˆåŠŸ\n", taskID)
			return nil
		})
	})

	if err != nil {
		fmt.Printf("  âŒ ä»»åŠ¡ %d æœ€ç»ˆå¤±è´¥: %v\n", taskID, err)
	}
}

// distributedSchedulingExample åˆ†å¸ƒå¼ä»»åŠ¡è°ƒåº¦ç¤ºä¾‹
func distributedSchedulingExample() {
	executor := goroutine.NewSafeExecutor()

	// åˆ›å»ºä»»åŠ¡è°ƒåº¦å™¨
	scheduler := NewTaskScheduler(executor)
	defer scheduler.Stop()

	// æ·»åŠ ä»»åŠ¡
	scheduler.AddTask("daily-report", func() error {
		fmt.Println("  ğŸ“Š ç”Ÿæˆæ—¥æŠ¥")
		time.Sleep(100 * time.Millisecond)
		return nil
	}, 1*time.Second)

	scheduler.AddTask("data-backup", func() error {
		fmt.Println("  ğŸ’¾ æ•°æ®å¤‡ä»½")
		time.Sleep(200 * time.Millisecond)
		return nil
	}, 2*time.Second)

	scheduler.AddTask("health-check", func() error {
		fmt.Println("  ğŸ¥ å¥åº·æ£€æŸ¥")
		time.Sleep(50 * time.Millisecond)
		return nil
	}, 500*time.Millisecond)

	// è¿è¡Œè°ƒåº¦å™¨
	scheduler.Start()

	// è¿è¡Œä¸€æ®µæ—¶é—´
	time.Sleep(5 * time.Second)

	// æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
	stats := scheduler.GetStats()
	fmt.Printf("  ğŸ“ˆ è°ƒåº¦å™¨ç»Ÿè®¡: æ€»ä»»åŠ¡=%d, æˆåŠŸ=%d, å¤±è´¥=%d\n",
		stats.TotalTasks, stats.SuccessfulTasks, stats.FailedTasks)
}

// TaskScheduler ä»»åŠ¡è°ƒåº¦å™¨
type TaskScheduler struct {
	executor *goroutine.SafeExecutor
	tasks    map[string]*ScheduledTask
	stopChan chan struct{}
	mu       sync.RWMutex
	stats    *SchedulerStats
}

type ScheduledTask struct {
	ID       string
	Fn       func() error
	Interval time.Duration
	StopChan chan struct{}
}

type SchedulerStats struct {
	TotalTasks      int64 `json:"total_tasks"`
	SuccessfulTasks int64 `json:"successful_tasks"`
	FailedTasks     int64 `json:"failed_tasks"`
	mu              sync.RWMutex
}

func NewTaskScheduler(executor *goroutine.SafeExecutor) *TaskScheduler {
	return &TaskScheduler{
		executor: executor,
		tasks:    make(map[string]*ScheduledTask),
		stopChan: make(chan struct{}),
		stats:    &SchedulerStats{},
	}
}

func (s *TaskScheduler) AddTask(id string, fn func() error, interval time.Duration) {
	s.mu.Lock()
	defer s.mu.Unlock()

	stopChan := make(chan struct{})
	task := &ScheduledTask{
		ID:       id,
		Fn:       fn,
		Interval: interval,
		StopChan: stopChan,
	}

	s.tasks[id] = task

	// å¯åŠ¨ä»»åŠ¡
	s.executor.Go(func() {
		ticker := time.NewTicker(interval)
		defer ticker.Stop()

		for {
			select {
			case <-ticker.C:
				s.executor.Go(func() {
					s.executeTask(task)
				})
			case <-stopChan:
				return
			}
		}
	})
}

func (s *TaskScheduler) executeTask(task *ScheduledTask) {
	s.stats.mu.Lock()
	s.stats.TotalTasks++
	s.stats.mu.Unlock()

	err := task.Fn()

	s.stats.mu.Lock()
	if err != nil {
		s.stats.FailedTasks++
	} else {
		s.stats.SuccessfulTasks++
	}
	s.stats.mu.Unlock()
}

func (s *TaskScheduler) Start() {
	// è°ƒåº¦å™¨å·²ç»åœ¨AddTaskæ—¶å¯åŠ¨
}

func (s *TaskScheduler) Stop() {
	s.mu.RLock()
	defer s.mu.RUnlock()

	for _, task := range s.tasks {
		close(task.StopChan)
	}
	close(s.stopChan)
}

func (s *TaskScheduler) GetStats() SchedulerStats {
	s.stats.mu.RLock()
	defer s.stats.mu.RUnlock()

	// è¿”å›å‰¯æœ¬ä»¥é¿å…é”å€¼å¤åˆ¶
	stats := *s.stats
	return stats
}

// realtimeMonitoringExample å®æ—¶ç›‘æ§å’Œå‘Šè­¦ç¤ºä¾‹
func realtimeMonitoringExample() {
	executor := goroutine.NewSafeExecutor()

	// åˆ›å»ºç›‘æ§å™¨
	monitor := goroutine.NewMonitor(executor, 500*time.Millisecond)

	// è®¾ç½®å‘Šè­¦é…ç½®
	monitor.SetAlertConfig(&goroutine.AlertConfig{
		MaxGoroutines: 20,
		MaxHeapAlloc:  100 * 1024 * 1024, // 100MB
		AlertHandler: func(alert *goroutine.Alert) {
			fmt.Printf("  ğŸš¨ å‘Šè­¦ [%s]: %s (å½“å‰å€¼: %v, é˜ˆå€¼: %v)\n",
				alert.Severity, alert.Message, alert.Value, alert.Threshold)
		},
	})

	// æ·»åŠ ç›‘æ§å¤„ç†å™¨
	monitor.AddHandler(func(stats *goroutine.MonitorStats) {
		fmt.Printf("  ğŸ“Š å®æ—¶ç›‘æ§: åç¨‹æ•°=%d, å †å†…å­˜=%d KB, GCæ¬¡æ•°=%d\n",
			stats.NumGoroutines, stats.HeapAlloc/1024, stats.NumGC)
	})

	// å¯åŠ¨ç›‘æ§
	monitor.Start()
	defer monitor.Stop()

	// æ¨¡æ‹Ÿé«˜è´Ÿè½½
	for i := 0; i < 30; i++ {
		executor.Go(func() {
			// æ¨¡æ‹Ÿå†…å­˜åˆ†é…
			data := make([]byte, 1024*1024) // 1MB
			_ = data
			time.Sleep(100 * time.Millisecond)
		})
	}

	// è¿è¡Œä¸€æ®µæ—¶é—´
	time.Sleep(3 * time.Second)

	// å¼ºåˆ¶GC
	monitor.ForceGC()
	fmt.Println("  ğŸ—‘ï¸ å¼ºåˆ¶åƒåœ¾å›æ”¶å®Œæˆ")
}

// gracefulShutdownExample ä¼˜é›…å…³é—­ç¤ºä¾‹
func gracefulShutdownExample() {
	executor := goroutine.NewSafeExecutor()

	// åˆ›å»ºåç¨‹æ± 
	config := &goroutine.PoolConfig{
		MaxWorkers: 5,
		QueueSize:  50,
		JobTimeout: 2 * time.Second,
	}
	pool := goroutine.NewPool(config)

	// è®¾ç½®ä¼˜é›…å…³é—­ä¿¡å·
	shutdown := make(chan struct{})

	// å¯åŠ¨ä¼˜é›…å…³é—­å¤„ç†å™¨
	executor.Go(func() {
		<-shutdown
		fmt.Println("  ğŸ›‘ å¼€å§‹ä¼˜é›…å…³é—­...")

		// åœæ­¢æ¥æ”¶æ–°ä»»åŠ¡
		pool.StopGracefully(5 * time.Second)

		fmt.Println("  âœ… ä¼˜é›…å…³é—­å®Œæˆ")
	})

	// æäº¤ä¸€äº›é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡
	for i := 0; i < 10; i++ {
		taskID := fmt.Sprintf("long-task-%d", i+1)
		pool.SubmitFunc(taskID, func() error {
			fmt.Printf("  ğŸ”„ æ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡ %s\n", taskID)
			time.Sleep(2 * time.Second)
			fmt.Printf("  âœ… é•¿æ—¶é—´ä»»åŠ¡ %s å®Œæˆ\n", taskID)
			return nil
		})
	}

	// ç­‰å¾…ä¸€æ®µæ—¶é—´
	time.Sleep(1 * time.Second)

	// è§¦å‘ä¼˜é›…å…³é—­
	close(shutdown)

	// ç­‰å¾…å…³é—­å®Œæˆ
	time.Sleep(6 * time.Second)
}
